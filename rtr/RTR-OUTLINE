=====================================
Top-level requirements for RTR server
-------------------------------------

T1. Provide timely, validated route origin information to multiple
    router clients, as specified in
    http://datatracker.ietf.org/doc/draft-ietf-sidr-rpki-rtr/

T2. Security requirement: Availability of route origin information.
    Client A must not be able to deny service to client B.

T3. Security requirement: (Currently optional) Integrity of route
    origin information.  RTR spec lists options such as TCP-AO, SSH,
    IPsec, and TLS.

Threat Model:

* Who/Motivation: Adversary wishing to alter routing through DoS of
  RTR server.
  
* Capability: Fully control/impersonate one or more RTR clients.  Can
  initiate arbitrary client connections, and send arbitrary data over
  RTR transport.

Explicit non-requirements:

* Confidentiality of route origin information is not required, since
  the information is publicly available.


===================================
Derived requirements for RTR server
-----------------------------------

D1. (Derived from T1). The RTR server will create periodic snapshots
    of the validated cache of ROAs, computing diffs and setting a new
    serial number each time.

D2. (Derived from T2). Basic authentication of client: firewall.  The RTR
    server is ASSUMED to sit behind a firewall that will (1) limit RTR
    clients to a set of pre-configured IP addresses, and (2) limit the
    number of concurrent connections from each IP address.
    
D3. (Derived from T2). Rate limit on queries.  The RTR server must limit
    the number of queries per connection, possibly by type of query, since
    reset queries can be expensive.

D4. (Derived from T1 and T2). Threads and timeouts.  Another way to abuse the
    system is when the server reads a message from a client and the
    actual transmission rate is *purposefully* very low. This should
    not stall all other clients.

D5. (Derived from T3). Future support for authenticated transport.
    RTR server is initially designed to support vanilla TCP only.
    Advanced functionality can be obtained through network shims such
    as netcat/ssh-subsystem, or stunnel.

D6. (Derived from T1 and T2).  The server should handle graceful
    shutdown, e.g. due to signal reception such as SIGINT.  A signal
    should not abruptly terminate the server process, which is the
    default behavior, but instead perform a graceful shutdown of all
    active connections. Signal handling procedure must be carefully
    written since it can easily induce race-conditions.

D7. (Derived from T1 and D2).  TCP keepalive.  To prevent inactivity
    from disconnecting the channel (e.g. due to firewall), and to
    reliably detect dead peers, keepalive should be enabled if the
    underlying OS supports it.


=======================
Problems to figure out:
-----------------------

 * In the current design, the connection control thread can spin on a socket that's read-ready, incrementing the corresponding semaphore many times before the connection thread reads all available data.
  * Possible fix: after incrementing a semaphore, remove the socket from the FD_SET and have the connection thread add it back somehow. This is probably problematic though.


===============
Design Overview
---------------

Threads (and job descriptions):
 . Main thread
 . Database threads
 . Connection control thread
 . Connection threads

Data structures and variables:
 . global db request queue
 . global vector of dbresponse semaphores (one per database-querying thread)
 . global notify state - latest locally-determined serial number
 . per-connection dbresponse queue
 . per-dbthread currently_processing vector {db request, dbresponse queue, dbresponse semaphore, dbstatement handle}
 . ??? per-dbrequest buffer length
 . ??? per-dbrequest operation completed boolean
 . ??? per-dbrequest array of PDUs

Synchronization structures:
 . dbresponse semaphores
 . more data semaphore
 . global notify state
 . 
 

===============
Detailed Design
---------------

Main thread:
  Create listening connection.
  Make queue of db requests {db request, queue, semaphore}.
  Make a vector of semaphores for the db request queue.
  Make a global notify state with a write-once/read-many lock, currently just the latest serial number.
  Call notify state update function on the global notify state.
  Repeat as many times as the desired initial number of database threads:
    Create a semaphore.
    Add the semaphore to the db request queue's vector of semaphores.
    Spawn a database thread with the semaphore and db request queue.
  Spawn a connection control thread, with the listening socket, db request queue and its semaphores, and global notify state
  Loop indefinitely:
    Sleep for some amount of time.
    Check the load on the database threads, adding or removing threads as needed.
    Call notify state update function on the global notify state.

Notify state update function:
  Static variable connection.
  If the connection isn't already present:
    Connect to database.
  Update the global notify state based on database queries.
 
Database thread:   
  Connect to database.
  Create currently processing vector of {db request, db response queue, db response semaphore, database statement handle}.
  Configured parameter buffer length: number of db responses to buffer per db request.
  Loop indefinitely:
    Block, trying to decrement the semaphore. ??? which semaphore?
    Let operation completed = false.
    For each member of currently processing:
      If the length of the db response queue is less than the buffer length:
        Fetch more data from the statement handle into an array of PDUs.
        Let is_done = false.
        Let more data semaphore = our semaphore. ??? member's response semaphore?
        If the statement handle is at the end:
          Let is_done = true.
          Let more data semaphore = NULL.
          Remove this member from currently processing.
          Append an end-of-data PDU to the array of PDUs.
        Add (db request, is_done, array of PDUs, more data semaphore) to db response queue.  ??? more data semaphore
        Increment db response semaphore.
        Let operation completed = true.
        Break the for loop.
    If there's a new request on the db request queue and not operation completed:
      Pop the db request queue.
      Create a new statement handle for the db request with the appropriate query.
      Add (db request, db response queue, db response semaphore, handle) to currently processing.
      Add (db request, false, array {start-of-data PDU} of PDUs, our semaphore) to db response queue. ??? start-of-data PDU could be more clear
      Increment db response semaphore.
      Increment our semaphore by buffer length - 1.  ??? which semaphore is "our" semaphore?

Connection control thread:
  Create a map of connection socket to semaphore.
  Loop indefinitely:
    select() on the listening socket and all connection sockets in the map.
    For each connection socket that's read-ready:
      Lookup the socket in the map and increment the associated semaphore.
    If the listening socket is accept-ready:
      accept()
      Create a semaphore.
      Add the just-created socket and semaphore to the map.
      Spawn a connection thread with the connection socket, semaphore, the global db request queue and its semaphores, and the global notify state.

Connection thread:
  Create a queue of db responses from the database {db request, bool is_done, array of response PDUs, more data semaphore}. // NOTE: this only has responses to one db request at a time
  Create a local queue of parsed and validated PDUs to be processed when the current db request is completed (i.e. is_done is set on a db response).
  Create a PDU reassembly buffer of constant size.
  Create a state variable in the READY state.
  Create a local notify state as a non-locked copy of the global notify state.
  Loop indefinitely:
    Block for at most some time interval, trying to decrement the semaphore.
    If the socket is read-ready:
      Block, reading and appending to the buffer only enough bytes to get the length field.
      If the partial PDU is invalid or the length is too large for the reassembly buffer:
        Send an error report PDU and log an error.
        Quit thread.
      Block, reading and appending to the buffer as many bytes as the length field specifies.
      Parse the PDU.
      If the PDU can be handled/responded to without any database interaction in the current state:
        Block, handling/responding as necessary.
      Else if state is RESPONDING:
        Add the PDU to the queue of to-be-processed PDUs.
      Else:
        Add (db request, db response queue, our semaphore) to the database request queue and increment each of the queue's semaphores.
        Set state to RESPONDING.
    Else if there is something on the db response queue:
      Pop it from the queue.
      If the more data semaphore is not NULL:
        Increment the more data semaphore.
      If any of the db response PDUs indicate an update to local notify state:
        Update local notify state as appropriate.
      Block, sending the db response PDUs.
      If its is_done is true:
        Set state to READY.
        While the to-be-processed queue is nonempty and state is READY:
          Pop the to-be-processed queue.
          If the PDU can be handled/responded to without any database interaction:
            Block, handling/responding as necessary.
          Else:
            Add (db request, db response queue, our semaphore) to the database request queue and increment each of the queue's semaphores.
            Set state to RESPONDING.
    If state is READY:
      Create tmp notify state as a non-locked copy of the global notify state.
      If local notify state is earlier than tmp notify state:
        Block, sending notify PDU(s) for the differences from local notify state to tmp notify state.
        Set local notify state to tmp notify state.

=====================
Example Program Flows
---------------------

Example 1: Flow of control during "Start or Restart"
http://tools.ietf.org/html/draft-ietf-sidr-rpki-rtr-19#section-6.1

   Cache                         Router
     ~                             ~
     | <----- Reset Query -------- | R requests data (or Serial Query)
     |                             |
     | ----- Cache Response -----> | C confirms request
     | ------- IPvX Prefix ------> | C sends zero or more
     | ------- IPvX Prefix ------> |   IPv4 and IPv6 Prefix
     | ------- IPvX Prefix ------> |   Payload PDUs
     | ------  End of Data ------> | C sends End of Data
     |                             |   and sends new serial
     ~                             ~

???


Example 2: Program flow during "Typical Exchange"
http://tools.ietf.org/html/draft-ietf-sidr-rpki-rtr-19#section-6.2

   Cache                         Router
     ~                             ~
     | -------- Notify ----------> |  (optional)
     |                             |
     | <----- Serial Query ------- | R requests data
     |                             |
     | ----- Cache Response -----> | C confirms request
     | ------- IPvX Prefix ------> | C sends zero or more
     | ------- IPvX Prefix ------> |   IPv4 and IPv6 Prefix
     | ------- IPvX Prefix ------> |   Payload PDUs
     | ------  End of Data ------> | C sends End of Data
     |                             |   and sends new serial
     ~                             ~

???


Example 3: Program flow during "Cache has No Data Available"
http://tools.ietf.org/html/draft-ietf-sidr-rpki-rtr-19#section-6.4

   Cache                         Router
     ~                             ~
     | <-----  Serial Query ------ | R requests data
     | ---- Error Report PDU ----> | C No Data Available
     ~                             ~

???


Example 4: Program flow in case of "Error"
???
