
The following are the steps required to run the APKI software.  Note that
steps 1-4 only need to be executed once at the beginning if everything goes
completely as planned.  Steps 5-8 have to be run periodically even under
ideal circumstances.  It is recommended that the user create a script
to run these four steps and have a cron job that executes this script
periodically.  All scripts for steps 3-8 are in the run_scripts directory.

(1) make the executables: In this directory, execute make, and this should
    create all the required executables in all the different directories.

(2) set environment variables: There are three environment variables used
    throughout the scripts and the code:
    APKI_DB - the name of the MySQL database used to hold the APKI data
    APKI_PORT - the port number used for the loader and feeder to talk
    APKI_ROOT - the full pathname of this directory (the top-level
      directory of the APKI tree)
    These environment variables will be set automatically to the
    following defaults by each of the scripts in the run_scripts directory:
    APKI_DB = apki
    APKI_PORT = 7344
    APKI_ROOT = current working directory, or one higher if in
                directory run_scripts
    If you ever want to run the code directly instead of running the
    scripts, make sure to set these yourself.

(3) initDB.sh: This script deletes the database, if any, with the name
    APKI_DB and sets up a new database with all the right tables.
    Be prepared to enter the root MySQL password twice.

(4) loader.sh: This starts the process that receives data from the feeder
    and loads it into the database.  Under ideal circumstances, this will
    continue to run forever, waiting for inputs from the feeder.

(5) rsync_pull.sh and feeder.sh: rsync_pull is a script that pulls
    the data from a set of repositories using rsync and then optionally
    loads them into the database used the feeder.sh script.
    rsync_pull.sh takes a single argument which is the name of a
    configuration file.  A sample configuration file called
    rsync_mock.config is included.  The configuration file tells the
    name of all remote repositories to be downloaded, the top-level
    directory for the local repository (with the REPOSITORY directory
    included here the suggested one), to top-level directory for storing
    the log files of the downloads (with LOGS the suggested directory),
    and whether or not to do the database load.

    If you want to do the database load separately or something fails to
    cause you to need to do the load separately, run the feeder.sh
    script directly, with the one argument being the name of the log file.

(6) garbage.sh: This checks for certificates that may have expired due
    to the passage of time, or crls that may have become stale due to
    the passage of time, and takes the appropriate actions.

(7) chaser.sh

(8) query.sh: This is the way to pull information out of the database and
    local repository.  There are two basic modes.

    The comprehensive query, indicated by the argument "-a", pulls all
    the valid ROAs from the repository and outputs a set of BGP filters
    specified by these ROAs.  To send the output to a file rather than the
    screen, include "-o <filename>" on the command line or just redirect
    the output.  Those ROAs whose trust chain includes a certificate whose
    CRL is currently stale are in a state that is between valid and invalid
    that we call "unknown", and by default we send the filters from these
    ROAs instead to a file called unknown.out.  To instead include them with
    the fully valid ROAs, include "-u valid" on the command line, and to
    completely ignore them, include "-u invalid" on the command line.

    The informational query provides the user with a means to see what
    is in the database without directly executing MySQL commands.
    The command "query.sh -l <type>", where type is cert, crl, or roa,
    provides a list of all the field names for a particular object type.
    ?????????????????
